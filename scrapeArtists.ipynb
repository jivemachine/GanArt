{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scraping art from wiki art using beautiful soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"art/wikiart\" # wherever you want the art to be saved\n",
    "base_url = \"https://www.wikiart.org\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through all artists by last name alphabetically\n",
    "# note: slight changes to this hunk of code will drastically change the art collected. \n",
    "for c in range(ord('a'), ord('z')+1):\n",
    "    char = chr(c)\n",
    "    artist_list_url = base_url + '/en/Alphabet/' + char + '/text-list'\n",
    "\n",
    "    genre_soup = BeautifulSoup(urllib.request.urlopen(artist_list_url), \"lxml\")\n",
    "    artist_list_main = genre_soup.find(\"main\")\n",
    "    lis = artist_list_main.find_all(\"li\")\n",
    "\n",
    "    # for each list element\n",
    "    for li in lis: \n",
    "        born = 0\n",
    "        died = 0\n",
    "\n",
    "        # get the date range\n",
    "        for line in li.text.splitlines():\n",
    "            if line.startswith(\",\") and \"-\" in line:\n",
    "                parts = line.split('-')\n",
    "                if len(parts) == 2:\n",
    "                    born = int(re.sub(\"[^0-9]\", \"\",parts[0]))\n",
    "                    died = int(re.sub(\"[^0-9]\", \"\",parts[1]))\n",
    "\n",
    "        # look for artists who may have created work that could in public domain\n",
    "        if born>1850 and died>0 and (born<1900 or died<1950):\n",
    "            link = li.find(\"a\")\n",
    "            artist = link.attrs[\"href\"]\n",
    "\n",
    "            if artist == \"/en/salvador-dali\": # skip Dali\n",
    "                continue\n",
    "\n",
    "            # get the artist's main page\n",
    "            artist_url = base_url + artist\n",
    "            artist_soup = BeautifulSoup(urllib.request.urlopen(artist_url), \"lxml\")\n",
    "\n",
    "            # only look for artists with the word abstract/avant-grde on their main page\n",
    "            if \"Abstract\" in artist_soup.text or \"abstract\" in artist_soup.text or \"Avant-garde\" \\\n",
    "                in artist_soup.text or \"avant-garde\" in artist_soup.text:\n",
    "                print(artist + \" \" + str(born) + \" - \" + str(died))\n",
    "\n",
    "                # get the artist's web page for the artwork\n",
    "                url = base_url + artist + '/all-works/text-list'\n",
    "                artist_work_soup = BeautifulSoup(urllib.request.urlopen(url), \"lxml\")\n",
    "\n",
    "                # get the main section\n",
    "                artist_main = artist_work_soup.find(\"main\")\n",
    "                image_count = 0\n",
    "                artist_name = artist.split(\"/\")[2]\n",
    "\n",
    "                # get the list of artwork\n",
    "                lis = artist_main.find_all(\"li\")\n",
    "\n",
    "                # for each list element\n",
    "                for li in lis:\n",
    "                    link = li.find(\"a\")\n",
    "\n",
    "                    if link != None:\n",
    "                        painting = link.attrs[\"href\"]\n",
    "\n",
    "                        # get the painting\n",
    "                        url = base_url + painting\n",
    "                        print(url)\n",
    "\n",
    "                        try:\n",
    "                            painting_soup = BeautifulSoup(urllib.request.urlopen(url), \"lxml\")\n",
    "\n",
    "                        except:\n",
    "                            print(\"error retreiving page\")\n",
    "                            continue\n",
    "\n",
    "                        # check the copyright\n",
    "                        if \"Public domain\" in painting_soup.text:\n",
    "\n",
    "                            #check the genre\n",
    "                            genre = painting_soup.find(\"span\", {\"itemprop\":\"genre\"})\n",
    "                            if genre != None and genre.text == \"abstract\":\n",
    "\n",
    "                                # get the url\n",
    "                                og_image = painting_soup.find(\"meta\", {\"property\":\"og:image\"})\n",
    "                                image_url = og_image[\"content\"].split(\"!\")[0] # ignore the !Large.jpg at the end\n",
    "                                print(image_url)\n",
    "\n",
    "                                save_path = file_path + \"/\" + artist_name + \"_\" + str(image_count) + \".jpg\"\n",
    "\n",
    "                                #download the file\n",
    "                                try:\n",
    "                                    print(\"downloading to \" + save_path)\n",
    "                                    time.sleep(0.2)  # try not to get a 403                    \n",
    "                                    urllib.request.urlretrieve(image_url, save_path)\n",
    "                                    image_count = image_count + 1\n",
    "                                except Exception as e:\n",
    "                                    print(\"failed downloading \" + image_url, e) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
